<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FINECITE: A Novel Approach For Fine-Grained Citation Context Analysis</title>
				<funder ref="#_6QNmtnH">
					<orgName type="full">Ministry of Education of Korea. Access</orgName>
				</funder>
				<funder ref="#_VB4arXq">
					<orgName type="full">NRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lasse</forename><surname>Jantsch</surname></persName>
							<email>lassejantsch@knu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Kyungpook National University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong-Jae</forename><surname>Koh</surname></persName>
							<email>djkoh@knu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Kyungpook National University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Seonghwan</forename><surname>Yoon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Kyungpook National University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jisu</forename><surname>Lee</surname></persName>
							<email>jisulee74@knu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Kyungpook National University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
							<email>anne.lauscher@uni-hamburg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Data Science Group</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Young-Kyoon</forename><surname>Suh</surname></persName>
							<email>yksuh@knu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Kyungpook National University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FINECITE: A Novel Approach For Fine-Grained Citation Context Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA35D3E3304D67FB562AEA92E23ADE6E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-13T06:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Citation context analysis (CCA) is a field of research studying the role and purpose of citation in scientific discourse. While most of the efforts in CCA have been focused on elaborate characterization schemata to assign function or intent labels to individual citations, the citation context as the basis for such a classification has received rather limited attention. This relative neglect, however, has led to the prevalence of vague definitions and restrictive assumptions, limiting the citation context in its expressiveness. It is a common practice, for example, to restrict the context to the citing sentence. While this simple context conceptualization might be sufficient to assign intent or function classes, it fails to cover the rich information of scientific discourse. To address this concern, we analyze the context conceptualizations of previous works and, to our knowledge, construct the first comprehensive context definition based on the semantic properties of the citing text. To evaluate this definition, we construct and publish the FINECITE corpus containing 1,056 manually annotated citation contexts. Our experiments on established CCA benchmarks demonstrate the effectiveness of our fine-grained context definition, showing improvements of up to 25% compared to state-of-the-art approaches. We make our code and data publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scientific research is inherently collaborative, with each discovery building upon a foundation of prior studies. To acknowledge previous work and provide credit, it is standard practice to include citations that connect past findings to new contributions. By embedding scientific progress and argumentation, citations serve a critical function that has been extensively examined-a research field known as citation context analysis (CCA) <ref type="bibr" target="#b25">(Kunnath et al., 2022;</ref><ref type="bibr" target="#b29">Swales, 1986)</ref>. In computational linguistics, CCA is mainly concerned with the automatic classification of citations along various dimensions, such as citation function <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b6">Cohan et al., 2019;</ref><ref type="bibr" target="#b15">Jurgens et al., 2018;</ref><ref type="bibr" target="#b31">Teufel et al., 2006)</ref>, sentiment <ref type="bibr" target="#b19">(Lauscher et al., 2017;</ref><ref type="bibr" target="#b0">Abu-Jbara et al., 2013;</ref><ref type="bibr" target="#b3">Athar and Teufel, 2012)</ref>, or influence <ref type="bibr" target="#b26">(Pride and Knoth, 2020;</ref><ref type="bibr" target="#b6">Cohan et al., 2019)</ref>. Given a passage of text surrounding a citation marker-referred to as the citation context-one or more classes from a predefined citation classification scheme are assigned.</p><p>Although a considerable amount of research has explored different classification schemes and methods, the citation context has received relatively little attention. This lack of focus has led to an absence of a comprehensive definition and datasets with overly simplistic and coarse-grained citation contexts <ref type="bibr" target="#b26">(Pride and Knoth, 2020;</ref><ref type="bibr" target="#b6">Cohan et al., 2019)</ref>.</p><p>To address this concern, we analyze different context conceptualizations in previous work and provide a new comprehensive definition based on the semantic information of the citing text. A visual comparison is provided in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>With our research and artifacts, we hope to spark new interest in the exploration of citation context information. Given the drastic capabilities of LLMs in zero-shot text understanding <ref type="bibr" target="#b5">(Brown et al., 2020;</ref><ref type="bibr" target="#b21">Lewis et al., 2020;</ref><ref type="bibr" target="#b32">Vaswani et al., 2017)</ref>, and the emergence of advanced language processing systems <ref type="bibr" target="#b21">(Lewis et al., 2020;</ref><ref type="bibr" target="#b9">Edge et al., 2024)</ref>, we argue that an improved understanding of contextual citation information is essential for improving interactive exploration of scientific argumentation.</p><p>Our contributions are the following:</p><p>• We analyze and formalize citation context conceptualizations in previous work.</p><p>• We propose, to our knowledge, the first finegrained citation context definition based on the semantic structure of the citing text.</p><p>• We construct and publish the FINECITE corpus comprising 1,056 manually annotated fine-grained citation contexts.</p><p>• We evaluate our context definition in two experiments and demonstrate its effectiveness on established benchmarks.</p><p>The rest of the paper is organized as follows. The subsequent section reviews relevant literature in the field of CCA and provides a formalization of task and context conceptualization. Section 3 introduces our citation context definition. In Section 4, we describe the curation process of the FINECITE corpus and provide core statistics. In Section 5, we assess the effectiveness of our context definition in both context extraction and citation classification. Section 6 summarizes our contributions and outlines directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>CCA is the subject of a substantial body of research with <ref type="bibr" target="#b11">(Garfield, 1972)</ref> often mentioned as one of the pioneering works. Reaching back to <ref type="bibr" target="#b31">(Teufel et al., 2006)</ref>, CCA research in computational linguistics is commonly conceptualized as learning a function F C representing the relationship of a citation context spanning s ∈ S to a set of classes c ∈ C. The task can thus be formalized as</p><formula xml:id="formula_0">F C (s) = arg max c∈C P F C (c | s),<label>(1)</label></formula><p>where P F C are the class probabilities emitted by F C . The classes C can represent various citation attributes, such as function <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b15">Jurgens et al., 2018;</ref><ref type="bibr" target="#b31">Teufel et al., 2006)</ref>, purpose <ref type="bibr" target="#b26">(Pride and Knoth, 2020;</ref><ref type="bibr" target="#b0">Abu-Jbara et al., 2013)</ref>, sentiment <ref type="bibr" target="#b3">(Athar and Teufel, 2012)</ref>, or intent <ref type="bibr" target="#b6">(Cohan et al., 2019)</ref>. For a comprehensive survey on CCA, refer to <ref type="bibr" target="#b25">(Kunnath et al., 2022)</ref>.</p><p>Despite the continued research in CCA, the introduction of new and larger datasets <ref type="bibr" target="#b6">(Cohan et al., 2019;</ref><ref type="bibr" target="#b15">Jurgens et al., 2018)</ref>, and updated methodology <ref type="bibr" target="#b28">(Shui et al., 2024;</ref><ref type="bibr" target="#b20">Lauscher et al., 2022;</ref><ref type="bibr" target="#b6">Cohan et al., 2019)</ref>, the simple modeling paradigm as described in Equation 1 prevailed. The popular SCICITE benchmark <ref type="bibr" target="#b6">(Cohan et al., 2019)</ref> even further simplifies the task by reducing the commonly used six-class framework of <ref type="bibr" target="#b15">(Jurgens et al., 2018)</ref> to a three-class schema. This simplicity leads to a low task complexity; however, it often fails to adequately represent the rich information present in the scientific texts <ref type="bibr" target="#b20">(Lauscher et al., 2022)</ref>. To capture a wider range of information, it is necessary to move beyond prevalent context span constraints and conceptualization on mutually exclusive classes. Table <ref type="table" target="#tab_0">1</ref> compares the relevant research.</p><p>Context Span Constraints. The optimal context spans S * can be defined such that S * = arg max</p><formula xml:id="formula_1">s i ∈S i P F (c i | s i ) | i ∈ I (2)</formula><p>where S i is the set of all possible context spans for one citation instance i ∈ I, and P F is the probabilities assigned by a function F representing some relationship between S and C.</p><p>As it is infeasible to solve Equation 2, previous work uses various assumptions to extract an approximate optimal context Ŝ * . The first common assumption is that S * can be approximated by a fixed-sized window surrounding the citation marker. The size of the context window varies between one <ref type="bibr" target="#b26">(Pride and Knoth, 2020;</ref><ref type="bibr" target="#b6">Cohan et al., 2019)</ref>, or multiple sentences <ref type="bibr" target="#b0">(Abu-Jbara et al., 2013;</ref><ref type="bibr" target="#b3">Athar and Teufel, 2012)</ref>, a specific number of characters <ref type="bibr" target="#b15">(Jurgens et al., 2018)</ref>, or the whole paragraph <ref type="bibr" target="#b31">(Teufel et al., 2006)</ref>. Some approaches <ref type="bibr" target="#b0">(Abu-Jbara et al., 2013;</ref><ref type="bibr" target="#b3">Athar and Teufel, 2012)</ref> allow for a non-context classification of context-window subsets, introducing a simple form of dynamic context spans. Only recent publications stress the importance of a fully dynamic approximation of S * <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b25">Nambanoor Kunnath et al., 2022)</ref> to conform to the situated structure of scientific argumentation. The second common assumption is that S * stretches continuously from the citation marker. Even though a notable number of publications technically allow for the extraction of non-contiguous contexts <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b0">Abu-Jbara et al., 2013;</ref><ref type="bibr" target="#b3">Athar and Teufel, 2012)</ref>, only one study <ref type="bibr" target="#b25">(Nambanoor Kunnath et al., 2022)</ref> particularly investigated the phenomenon. They directly compared a non-contiguous context window with a smaller contiguous version and found that the former slightly outperforms the latter.</p><p>Thirdly, S * is often conceptualized with the sentence assumed to be the atomic unit of information <ref type="bibr" target="#b6">(Cohan et al., 2019;</ref><ref type="bibr" target="#b25">Nambanoor Kunnath et al., 2022;</ref><ref type="bibr" target="#b20">Lauscher et al., 2022)</ref>. In certain cases, however, this is not necessarily the case. <ref type="bibr" target="#b1">Abu-Jbara and Radev (2012)</ref>, for instance, shows evidently that sub-sentence segmentation is necessary to approximate S * for sentences with multiple citations. While their focus lies on the multi-citation setting, we also observe sub-sentence context granularity in other settings.</p><p>Conceptual Restraints. Next to the restrictive assumptions imposed on the context span, there are conceptual restraints limiting the expressiveness of citation contexts. In nearly all previous work, the context is conceptualized as</p><formula xml:id="formula_2">Ŝ * C ≈ arg max s i ∈S ′ i P F C (c i | s i ) | i ∈ I ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">S ′ i = {s i ∈ S i | ∃c ∈ C : F C (s i ) = c} . (4)</formula><p>This formulation captures that the context approximation Ŝ * C only contains spans S ′ that have a clear association with a class in C. In other words, the citation context is conceptualized based on the classification schema represented through F C and not based on the semantic information of the text.</p><p>Most previous works additionally restrain their conceptualization by defining the relationship between S and C as mutually exclusive <ref type="bibr" target="#b26">(Pride and Knoth, 2020;</ref><ref type="bibr" target="#b6">Cohan et al., 2019;</ref><ref type="bibr" target="#b15">Jurgens et al., 2018)</ref>. This restricts the citation context further, as scientific discourse is faceted and can have multiple explanations <ref type="bibr" target="#b20">(Lauscher et al., 2022)</ref>. Lauscher et al. addressed this by creating the MULTICITE dataset, designed for multi-sentence, multi-function classification. They find that nearly one in five citations have at least two classes, with some reaching up to four. While this represents a step forward, it does not resolve the underlying limitation of defining citation context solely through the lens of the classification schema.</p><p>The only previous publication that defines a context based on semantic information from the vicinity of the citation marker is from <ref type="bibr" target="#b10">Ferrod et al. (2021)</ref>. They distinguish between the citation object and the context, where the former is the cited concept and the latter background information, or constraints on the citation object. While this goes in a similar direction to this work, their definition lags in completeness and only works on a subset of instances. To our knowledge, we are the first to propose a comprehensive citation context definition that is disjoint from the classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fine-Grained Citation Context</head><p>In this section, we propose and formalize our fine-grained context definition.</p><p>Semantic Dimensions. We base our context definition on previous research on argumentative structures in scientific texts. <ref type="bibr" target="#b30">Teufel (2014)</ref> categorizes scientific argumentation along four principal dimensions: (i) statements about the author's own work (citing paper), (ii) properties of existing solutions (cited papers), (iii) the relationships between existing solutions and the author's contribution, and (iv) general properties of the research space. We apply this framework to the field of CCA and define the following three context dimensions.</p><p>The first dimension of the citation context is the information the citing author references from the cited paper. In the example "Our paper extends the citation labeling scheme of &lt;CITATION&gt; and then reports similarities..." the phrase, "the citation labeling scheme of &lt;CITATION&gt;," describes here what information from the cited paper the author is referring to. This dimension highly correlates with (ii)-the properties of existing solutions, and is somewhat related to the citation object of <ref type="bibr" target="#b10">Ferrod et al. (2021)</ref>. In the following, we refer to this dimension as the Information Dimension (INF).</p><p>The second dimension describes the relationship between the citing and the cited work and corresponds to (iii) in <ref type="bibr" target="#b30">Teufel (2014)</ref>. In the excerpt " :: Our ::::: paper ::::::: extends the citation labeling scheme of &lt;CITATION&gt; and then reports similarities..." the passage "our paper extends" describes how the author uses the cited information in their work. While use constitutes a substantial fraction of occurring relations, this dimension also includes other forms of perception, such as comparison, evaluation, and judgment. In the following, we refer to it as the Perception Dimension (PERC).</p><p>While these two dimensions cover the most critical aspects of a citation context,-what is cited and how is it perceived or used-they do not necessarily include the information of why the author chose to include a citation.</p><p>"Unlike recent language representation models &lt;CITATION&gt;, ... .... BERT ... . is ... ..... .... designed .. .. to .... ..... .. pretrain . .. .. . . deep . . . . . . . . . . . . . . . bidirectional .. ..... .... ..... .. representations . .... .... from..."</p><p>Here, the reason the author included this citation is to emphasize a novel property of the citing paper's contribution. In <ref type="bibr" target="#b30">Teufel's (2014)</ref> framework, this falls under the semantic class (i)-properties of the citing work-and is neither considered in the INF nor the PERC dimension. In other instances, such a motivating factor could be related to a property of the research space (iv) or other direct citations (ii, iii). We categorize these passages, which explain why a citation was included, as the Background Dimension (BACK) of a citation.</p><p>Formal Definition. To formalize our finegrained citation context, we expand upon Equation 2 by removing the task dependency and incorporating semantic dimensions outlined above. Specifically, we define the task-independent, approximately optimal citation context Ŝ * as:</p><formula xml:id="formula_4">Ŝ * := {s * i | i ∈ I} ,<label>(5)</label></formula><p>where</p><formula xml:id="formula_5">s * i = {s i ∈ S i | ∃d ∈ D : F D (s i ) = d} ,<label>(6)</label></formula><formula xml:id="formula_6">D = {INF, PERC, BACK}<label>(7)</label></formula><p>is the set of semantic dimensions defined in this Section, and F D represents the semantic relationship of the surrounding text to the citation. We further formalize three structural properties of citation context spans ŝ * ∈ Ŝ * :</p><p>• Dynamicity: The length | ŝ * | is dynamic and adapts to the situated structure of the enclosing argumentation.</p><p>• Non-Contiguity: ŝ * may consist of multiple disjoint spans allowing for skip-structured selection of relevant information.</p><p>• Sub-Sentence Granularity: ŝ * is constructed on sub-sentence granularity, enabling a finegrained representation of the argumentative structure.</p><p>These properties collectively define a flexible and semantically motivated citation context that diverges from the constrained approximations of previous works. We provide a detailed empirical discussion of their relevance in Section 4.2 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FINECITE Corpus</head><p>Using the definition in Section 3, we create the FINECITE corpus. With the dataset creation, we aim to (i) assess whether the theoretical framework practically applies to scientific texts, (ii) investigate the assumption on the semantic dimensions and structure of citation contexts, and (iii) create a resource for the evaluation of the framework on established CCA Benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Construction</head><p>We construct the corpus in the following steps.</p><p>Step 1: Procurement. The FINECITE dataset was built from a subset of ACL Anthology Network Corpus <ref type="bibr" target="#b27">(Radev et al., 2009)</ref>. The ACL Anthology Network contains over 80K papers from several ACL conferences and other venues in computational linguistics. We extracted the full paper text, including citations, using GROBID (GROBID, 2024). Documents containing faulty meta-information, languages other than English, and miscellaneous documents with &lt;3 sections and &lt;5 references were excluded.</p><p>From the remaining documents, we sampled 1,056 paragraphs, each containing one citation marker highlighted for annotation.</p><p>Step 2: Guideline creation. The annotation guidelines comprise best practices and rules for the context annotation. The instructions were created based on the definition presented in Section 3 and further iteratively refined to better handle ambiguous cases. For each iteration, several annotators completed five to ten tasks separately and subsequently discussed differences. Afterwards, the guidelines were updated to reduce ambiguity for the next iteration. In total, five iterations were performed. The complete Annotation Guidelines can be found in Appendix E.</p><p>Step 3: Annotation. The annotation was performed for each paragraph separately. The annotator was asked to read the paragraph carefully and annotate the context of the highlighted citation based on the guidelines. To provide further information in case of ambiguity, additional information, like the surrounding paragraphs and metadata about citing and cited papers, was provided in the annotation tool. A detailed description of the annotation platform is provided in Appendix A.</p><p>All annotators had previous experience with scientific literature and were carefully trained on the Annotation Guidelines. The compensation followed locally typical rates for research assistants.</p><p>Step 4: Validation. To ensure the annotation quality, we monitored several inter-annotator agreement (IAA) metrics on 10% of the annotations. We measured both F-measure commonly used for span annotations with open bounds <ref type="bibr" target="#b14">(Hripcsak and Rothschild, 2005)</ref>, and Cohens κ <ref type="bibr" target="#b7">(Cohen, 1960)</ref> for the agreement on label assignment above that expected by chance. To capture different aspects of the annotation process separately, we provide IAA for the whole context (F 1 total ), and for each scope separately (F 1 inf , F 1 perc , F 1 back ). The F 1 macro is the mean over F 1 inf , F 1 perc , and F 1 back . While the metrics follow the standard definition, we provide a formal definition in Appendix B.</p><p>The F 1 total after the annotation process was 0.75, indicating an overall good agreement. The separate IAA on the context dimensions, however, is considerably lower. While the F 1 inf is with a score of 0.65 the highest, the F 1 perc is at 0.42 and the F 1 back at 0.34. The F 1 macro lies at 0.48 and the κ on the validation samples was 0.55.</p><p>While these values are in the typical range for annotation of scientific literature <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b10">Ferrod et al., 2021;</ref><ref type="bibr" target="#b18">Lauscher et al., 2018)</ref>, they highlight the task complexity. The moderate F 1 macro , despite a rather high F 1 total , indicates that while annotators often struggle to clearly distinguish between the dimensions, they have a good sense of what constitutes relevant information. PERC and BACK seem especially ambiguous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Corpus Statistics</head><p>The FINECITE corpus contains 1,056 fine-grained citation contexts for paragraphs from 72 scientific papers. Overall, INF accounts for 27%, PERC for 35%, and BACK for 38% of the annotated words. The average context length is ∼45 words and is approximately normally distributed with a long tail toward the upper end. The main contribution to the longer contexts is the BACK dimension. While BACK comprises about 8 words (30%) in contexts shorter than 40 words, it expands to an average of 54 words (43%) in contexts exceeding 100 words. Combined with the low agreement score on BACK, this might indicate that a clearer delimitation of the dimension might be helpful. Figure <ref type="figure" target="#fig_2">2</ref> provides an expanded visualization of the corpus statistics.</p><p>To evaluate the context span properties presented in Section 3, we apply context restrictions commonly used in prior work to the contexts in FINECITE and compare them to the fine-grained gold labels. We report F1-score and %-Match met-   rics for fixed-size windows of one, two, and four sentences, as well as for the longest contiguous sub-context and contexts extended to the next sentence boundary. We ignore dimension classes to highlight the structural properties and allow a twoword tolerance in the %-Match metric. Results are shown in Table <ref type="table" target="#tab_2">2</ref>.</p><p>Restricting the context to a fixed number of sentences results in a considerable error in both the F1-score and %-Match. The %-Match scores suggest that single-sentence contexts offer the best performance among fixed-size context windows; however, they fall short of capturing a majority of instances. Contiguity exhibits a minor error compared to fixed context windows, indicating that non-contiguity occurs less, and non-contiguous segments are rather small in size. Surprisingly, the total F1-score error induced through sentence segmentation is relatively small. For the assignment of fine-grained dimension labels, sub-sentence segmentation is, however, a necessary property.</p><p>Overall, the results affirm the significance of the three structural assumptions-sub-sentence segmentation, non-contiguity, and dynamic context-for a fine-grained citation context extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we evaluate the FINECITE dataset on two tasks: (i) extraction of fine-grained citation contexts, and (ii) citation classification on standard CCA benchmarks using fine-grained context information extracted in (i).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Citation Context Extraction</head><p>Ensuring that common extraction models can reliably learn to identify citation contexts is crucial for the effective application of the presented fine-grained context definition.</p><p>Data preparation. We utilized the same samples used in the evaluation of the annotation process as the test set, with the remaining samples reserved for training and validation. We evaluate extraction on (i) uniform token labels and (ii) commonly used IOB (Inside-Outside-Beginning) labels.</p><p>Extraction model. For all extraction approaches, we use a SCIBERT <ref type="bibr" target="#b4">(Beltagy et al., 2019)</ref> encoder model. SCIBERT is a BERT-like encoder-only transformer, pre-trained on scientific literature. To cover several common sequence extraction approaches, we evaluate three different classification heads: a linear, a Bi-LSTM <ref type="bibr" target="#b13">(Hochreiter and Schmidhuber, 1997)</ref>, and a conditional random field (CRF) <ref type="bibr" target="#b17">(Lafferty et al., 2001)</ref> classifier.</p><p>Experiment setup. We used the pre-trained weights of SCIBERT from huggingface transformers <ref type="bibr" target="#b34">(Wolf et al., 2020)</ref> and finetuned the whole model (encoder + cls-head) using AdamW <ref type="bibr" target="#b22">(Loshchilov and Hutter, 2019)</ref>  linear warm-up ratio of 5% and a peak learning rate of 5e-5. All models were fine-tuned using early stopping with a patience of three epochs, a batch size of 4, and a dropout rate of 0.1. To address class imbalance, we additionally applied weighted cross-entropy loss. The training was conducted on an NVIDIA A100 GPU. We evaluated the F1 scores described in Section 4.1.</p><p>Result. Table <ref type="table" target="#tab_3">3</ref> shows the results of F 1 total and F 1 macro . See Appendix D for extended results.</p><p>We observe that all three extraction approaches reach higher F1 scores than those measured during the annotation process. The variance between the different classifiers is rather small. The CRF classifier exhibits the highest F 1 total score of 0.787, while the Bi-LSTM classifier dominates the F 1 macro metric with 0.56. The linear classifier achieves an F 1 macro of 0.557 and an F 1 total of 0.77, only slightly lower than the other approaches.</p><p>The best results were achieved using IOB labels for linear and Bi-LSTM classifiers, whereas the CRF classifier worked better with uniform labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Citation Context Classification</head><p>To showcase the benefits of fine-grained contexts in a competitive setting, we provide a broad comparison with previous work using the citation classification task.</p><p>Data. We evaluate fine-grained contexts on four commonly used CCA benchmarks.</p><p>• ACL-ARC <ref type="bibr" target="#b15">(Jurgens et al., 2018)</ref> comprises 1,933 labeled citations following a six-label classification schema introduced in the paper.</p><p>All samples originate exclusively from the computational linguistics domain.</p><p>• ACT2 (N. <ref type="bibr" target="#b24">Kunnath et al., 2021)</ref> is a larger, mixed-domain collection with 4,000 anno-tated citations labeled with the schema used for the ACL-ARC dataset.</p><p>• SCICITE <ref type="bibr" target="#b6">(Cohan et al., 2019)</ref>, also multidomains, contains 11,000 samples, annotated with a simple three-class annotation schema.</p><p>• MULTICITE <ref type="bibr" target="#b20">(Lauscher et al., 2022</ref>) is a multi-sentence, multi-label dataset annotated with seven citation function classes based on the scheme used in ACL-ARC. With 12,653 annotated citations, it is the biggest dataset.</p><p>Although ACL-ARC and ACT2 are primarily modeled using the citing sentence alone, we perform extraction on an extended window containing multiple sentences before and after the citation. SCICITE does not provide text exceeding the citing sentence, which drastically restricts the extraction of our fine-grained context.</p><p>To reduce the model's tendency to memorize author names, we conceal the targeted and other citations behind &lt;TARGET_CITATION/&gt; and &lt;CITATION/&gt; tags, respectively. Each dataset is divided into approximately 85% training and 15% testing. For the FINECITE approaches, we extract the fine-grained context using the extraction approach presented in Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification model.</head><p>We considered four baselines for the classification task: (i) the scaffolding approach presented in <ref type="bibr" target="#b6">Cohan et al. (2019)</ref>, (ii) the best-performing citation classification model from the 3C classification task 2021 (N. <ref type="bibr" target="#b24">Kunnath et al., 2021</ref>)-a SCIBERT model with a linear classification head <ref type="bibr" target="#b23">(Maheshwari et al., 2021)</ref>, (iii) GPT-4o <ref type="bibr" target="#b2">(Achiam et al., 2023)</ref>, and (iv) SCITULU 70B <ref type="bibr" target="#b33">(Wadden et al., 2024)</ref>-an instruction-tuned LLM for scientific literature. (i) and (ii) were fine-tuned on the training split, and (iii) and (iv) were evaluated in a zero-shot setting. The FINECITE approaches use SCIBERT <ref type="bibr" target="#b4">(Beltagy et al., 2019)</ref> embeddings and a linear classification head similar to (ii). Instead of using CLS pooling, we use mean pooling over tokens belonging to the same dimension. The resulting dimension embeddings were concatenated and passed to the classification head.</p><p>Experiment setup. We utilized the pre-trained SCIBERT weights as mentioned above. The best performance was achieved using AdamW <ref type="bibr" target="#b22">(Loshchilov and Hutter, 2019)</ref> conducted on an NVIDIA A100 GPU. The optimal learning rate, batch size, and dropout for each dataset are provided in Appendix C. For all fine-tuned models, the performance was evaluated over five consecutive seeds.</p><p>Result. Table <ref type="table" target="#tab_4">4</ref> exhibits the macro-F1 and standard deviation for each dataset. Detailed results including class scores are shown in Appendix D. Among the baselines, SCIBERT achieves the highest average macro-F1 (0.546), followed by the SCAFFOLDS approach (0.453). Both GPT-4o (0.43) and SCITULU 70B (0.405) perform lower. These results show that finetuned encoder models have a considerably better conceptualization of the citation task than LLMs in a zero-shot setting. We further observe that the SCAFFOLDS approach exhibits a high standard deviation on the ACL-ARC tasks, as it struggles to predict minority labels correctly on the smaller dataset.</p><p>The FINECITE models introduced in this work outperform the baselines across all datasets. Among them, the context extracted with the Linear classification head achieves the best overall performance, with an average macro-F1 of 0.579. The context from the BiLST and CRF classifier only perform slightly lower with an average macro-F1 of 0.574 and 0.571, respectively. Comparing the performance on a per-dataset basis reveals a more nuanced pattern. The largest increase can be observed on the ACT2 dataset with a 25% increase over the strongest baseline, followed by a 13% increase on the ACL-ARC dataset. We explain the relatively low performance increases on MULTICITE by considering that the dataset already provides a dynamic context, leaving limited advantage for fine-grained contexts. The performance</p><p>APPROACH ACL-ARC ACT2 macro st. dev. macro st. dev. Context Dimensions w/o INF 0.556 0.017 0.277 0.013 w/o PERC 0.563 0.019 0.259 0.036 w/o BACK 0.56 0.019 0.253 0.024 Mean Pooling Dimensions 0.584 0.014 0.302 0.02 Weighted tok 0.542 0.013 0.281 0.019 Weighted dim 0.573 0.015 0.28 0.015 Table 5: Ablation on context dimensions and pooling on the SCICITE benchmark further stresses that for the extraction of comprehensive fine-grained context, the citing sentence is not sufficient. Overall, the results demonstrate that the fine-grained citation context proposed in this work captures a more comprehensive citation representation than other conceptualizations in previous work.</p><p>Ablation. We provide ablation on the context dimensions, pooling method, and domain shift for a further analysis of the proposed fine-grained citation contexts. The dimension and pooling ablation were done on the ACL-ARC and ACT2 datasets. We create two new datasets (ACT 2, ACT 2 ′ D ) for the evaluation on domain shift.</p><p>With the ablation on the citation dimensions (Table <ref type="table">5</ref>) we investigate the significance of the INF, PERC, and BACK dimensions for classification performance. Our analysis shows that removing any of the three citation dimensions leads to a performance drop for both datasets. While the decrease in performance on the ACL dataset is similar for all three dimensions, for the ACT2 benchmark PERC and BACK exert greater influence. This highlights that despite the low extraction performance, PERC and BACK contain essential information for the citation classification task.</p><p>The ablation on pooling strategies (Table <ref type="table">5</ref>) evaluates whether pooling citation dimensions separately improves performance over simpler alternatives. We compare this approach to token-weighted pooling, which ignores citation dimensions, and a dimension-weighted method. On both datasets, separate dimension pooling yields better results. Although the performance gap is modest, it indicates that modeling citation dimensions individually enhances representation quality, reinforcing the value of our context definition.</p><p>As the FINECITE dataset only consists of samples from the computational linguistics domain, there might be a domain bias in the context extraction. To evaluate whether this compromises domain adaptation performance on the classification task, we provide an ablation on two new datasets (ACT2 ′ , ACT2 ′ D ) constructed from the multi-domain ACT2 benchmark (Table <ref type="table" target="#tab_6">6</ref>). The ACT2 ′ D contains samples from computational linguistics and STEM domains in its training split, and samples from medicine and social sciences in its test split, thus evaluating domain adaptation. The ACT2 ′ , on the other hand, contains samples from all domains in both splits while following the same split sizes. We provide the macro-F1 results on the test set for the strongest baseline and our approach, and analyze the difference-in-difference estimator between the two approaches.</p><p>For both models, we observe a substantial drop in performance when evaluated out-of-domain. Our approach retains a slightly larger margin, leading to a negative difference-in-difference estimate of -0.024. Despite this indicating that our model approach performs slightly worse on domain adaptation, the performance gains of using fine-grained contexts outweigh this drawback in overall effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Percentage Points</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduced a novel approach to defining citation contexts, aiming to foster new research in citation context analysis. We proposed a conceptual framework that characterizes citation context based on semantic dimensions and structural properties. Subsequently, we described the curation of the FINECITE corpus-a first resource for fine-grained citation contexts-and analyzed core statistics. Our experiments demonstrated that our context definition is practically applicable and leads to improved performance on established CCA benchmarks compared to state-of-the-art methods.</p><p>In future work, we will focus on expanding the dataset to a wider range of scientific texts and domains and further refining our context definition. Additionally, we plan to explore applications, such as retrieval-augmented generation (RAG) <ref type="bibr" target="#b21">(Lewis et al., 2020;</ref><ref type="bibr" target="#b9">Edge et al., 2024)</ref> and question-answering (Q&amp;A) frameworks <ref type="bibr" target="#b20">(Lauscher et al., 2022;</ref><ref type="bibr" target="#b8">Dasigi et al., 2021)</ref>, to support interactive exploration of scientific argumentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>This work presents the first dataset of its kind, albeit with limitations in both size and domain coverage. The accompanying evaluation and analysis should be understood within this restricted scope and may not generalize to broader contexts. The objective is to establish a comprehensive definition of citation contexts and provide a resource and baseline for further analysis. Additionally, although our context definition is intended to be taskindependent, our evaluation is limited to a subset of tasks due to constraints in space and resources.</p></div>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>(a) Distribution of context length (words). (b) Label distribution per context length (words).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Results of statistical analysis of the FINECITE dataset, showing the variation of context length and its interrelation with label distribution.</figDesc><graphic coords="6,91.92,79.78,185.53,139.28" type="bitmap"/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: The Annotation Interface: Located on the left is the annotation toolbar, with the color-coded marker for each context scope, an ERASE tool, and the RESET button. The center is the working area where the annotation task is displayed and annotated. On the right side, meta-information regarding the citing and cited papers is provided, and alternatively, a comment section can be accessed to leave questions or notes. The navigation bar on the bottom gives (from left to right) access to the annotation guidelines, the comment section, and three buttons for returning to the previous task, skipping, or submitting the current task.</figDesc><graphic coords="13,70.86,70.85,430.89,191.79" type="bitmap"/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Four</head><figDesc>different types of tags can occur in the annotation task ([REF],[GREF],[TREF],[GTREF]). The 'REF' part of the tag generally refers to 'Reference,' meaning that each tag is some kind of placeholder for one or multiple references. More particularly, the '[REF]' tag replaces one single reference (e.g. (Goodfellow 2012) → [REF]), and the [GREF] tag replaces a Group of References (e.g. (Cohan et al. 2018, Jha et al. 2016) → [GREF]). Further, there are two different versions of the [REF] and the [GREF] tag, which indicate that they are the Target of the annotation task. The 'T' in the [TREF] and the [GTREF] tag means Target. Each annotation task will have only one target reference, but multiple other single or group references might exist.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>be seen in BERT[TREF].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Structural comparison of previous work in computational linguistics on CCA (NO. CLS.</figDesc><table><row><cell>AUTHOR (YEAR)</cell><cell>ASPECT</cell><cell>NO. CLS.</cell><cell cols="2">EXCL SEM</cell><cell cols="3">DYN NON-C SUB-S</cell><cell/></row><row><cell>Lauscher et al. (2022)</cell><cell>function</cell><cell>7</cell><cell>✔</cell><cell>✘</cell><cell>✔</cell><cell>✔</cell><cell>✘</cell><cell/></row><row><cell>Kunnath et al. (2022)</cell><cell>function</cell><cell>6</cell><cell>✘</cell><cell>✘</cell><cell>✔</cell><cell>✔</cell><cell>✘</cell><cell/></row><row><cell>Ferrod et al. (2021)</cell><cell>intent</cell><cell>5</cell><cell>✘</cell><cell>✔</cell><cell>(✔)</cell><cell>(✔)</cell><cell>✔</cell><cell/></row><row><cell>Pride and Knoth (2020)</cell><cell>purpose</cell><cell>6</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell/></row><row><cell>Cohan et al. (2019) Jurgens et al. (2018)</cell><cell>intent function</cell><cell>3 6</cell><cell>✘ ✘</cell><cell>✘ ✘</cell><cell>✘ ✘</cell><cell>✘ ✘</cell><cell>✘ ✘</cell><cell>‚</cell></row><row><cell>Abu-Jbara et al. (2013)</cell><cell>purpose</cell><cell>6</cell><cell>✘</cell><cell>✘</cell><cell>(✔)</cell><cell>✔</cell><cell>✘</cell><cell/></row><row><cell>Athar and Teufel (2012)</cell><cell>sentiment</cell><cell>3</cell><cell>✘</cell><cell>✘</cell><cell>(✔)</cell><cell>✔</cell><cell>✘</cell><cell/></row><row><cell>Abu-Jbara and Radev (2012)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>✔</cell><cell>(✔)</cell><cell>(✔)</cell><cell>✔</cell><cell/></row><row><cell>Teufel et al. (2006)</cell><cell>function</cell><cell>11</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell>✘</cell><cell/></row><row><cell>FINECITE (this work)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>✔</cell><cell>✔</cell><cell>✔</cell><cell>✔</cell><cell/></row></table><note><p>= Number of classes, EXCL = Mutually exclusive labels, SEM = Semantic-based conceptualization, DYN = Dynamic context, NON-C = Non-contiguous context, SUB-S = Sub-sentence context)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Experiments on context restrictions compared to the gold context from FINECITE</figDesc><table><row><cell>RESTRICTION</cell><cell>F1-Score</cell><cell>%-Match</cell></row><row><cell>One Sentence</cell><cell>0.679</cell><cell>30.4</cell></row><row><cell>Two Sentences</cell><cell>0.716</cell><cell>23.6</cell></row><row><cell>Four Sentences</cell><cell>0.704</cell><cell>18.6</cell></row><row><cell>Contiguous</cell><cell>0.863</cell><cell>64.6</cell></row><row><cell>Sentence Segments</cell><cell>0.951</cell><cell>70.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>with aExtraction results on the FINECITE dataset</figDesc><table><row><cell/><cell>F 1 total</cell><cell>F 1macro</cell></row><row><cell cols="2">Inter Annotator Agreement</cell><cell/></row><row><cell>Human (Annotation)</cell><cell>0.75</cell><cell>0.48</cell></row><row><cell cols="2">Extraction Task</cell><cell/></row><row><cell>SCIBERT w. Linear</cell><cell>0.77</cell><cell>0.557</cell></row><row><cell>SCIBERT w. BiLSTM</cell><cell>0.759</cell><cell>0.56</cell></row><row><cell>SCIBERT w. CRF</cell><cell>0.787</cell><cell>0.521</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>, early stopping, and a linear warm-up of 5%. The training was Results of the citation classification task on the four benchmarks ACL-ARC, ACT2, SCICITE, and MULTICITE. The standard deviation (st. dev.) is calculated over five consecutive seeds.</figDesc><table><row><cell>APPROACH</cell><cell cols="2">ACL-ARC macro st. dev.</cell><cell cols="2">ACT2 macro st. dev.</cell><cell cols="2">SCICITE macro st. dev.</cell><cell cols="2">MULTICITE macro st. dev.</cell><cell>MEAN</cell></row><row><cell/><cell/><cell/><cell cols="3">Baseline Approaches</cell><cell/><cell/><cell/><cell/></row><row><cell>SCAFFOLDS</cell><cell>0.377</cell><cell>0.067</cell><cell>0.205</cell><cell>0.026</cell><cell>0.821</cell><cell>0.010</cell><cell>0.409</cell><cell>0.036</cell><cell>0.453</cell></row><row><cell>SCIBERT</cell><cell>0.517</cell><cell>0.018</cell><cell>0.242</cell><cell>0.012</cell><cell>0.841</cell><cell>0.005</cell><cell>0.584</cell><cell>0.006</cell><cell>0.546</cell></row><row><cell>GPT 4O</cell><cell>0.401</cell><cell>-</cell><cell>0.117</cell><cell>-</cell><cell>0.766</cell><cell>-</cell><cell>0.434</cell><cell>-</cell><cell>0.43</cell></row><row><cell>SCITULU 70B</cell><cell>0.37</cell><cell>-</cell><cell>0.114</cell><cell>-</cell><cell>0.783</cell><cell>-</cell><cell>0.353</cell><cell>-</cell><cell>0.405</cell></row><row><cell/><cell/><cell/><cell cols="3">FINECITE Approaches</cell><cell/><cell/><cell/><cell/></row><row><cell>SCIBERT (Linear)</cell><cell>0.572</cell><cell>0.018</cell><cell>0.302</cell><cell>0.02</cell><cell>0.84</cell><cell>0.002</cell><cell>0.603</cell><cell>0.021</cell><cell>0.579</cell></row><row><cell cols="2">SCIBERT (BiLSTM) 0.584</cell><cell>0.014</cell><cell>0.282</cell><cell>0.014</cell><cell>0.845</cell><cell>0.003</cell><cell>0.601</cell><cell>0.005</cell><cell>0.578</cell></row><row><cell>SCIBERT (CRF)</cell><cell>0.563</cell><cell>0.007</cell><cell>0.274</cell><cell>0.024</cell><cell>0.841</cell><cell>0.002</cell><cell>0.606</cell><cell>0.010</cell><cell>0.571</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Ablation on Domain shift.</figDesc><table><row><cell/><cell/><cell>D</cell><cell>∆</cell><cell>%</cell></row><row><cell>SCIBERT</cell><cell>0.345</cell><cell>0.228</cell><cell cols="2">-0.117 -33.9%</cell></row><row><cell>FINECITE</cell><cell>0.404</cell><cell>0.263</cell><cell cols="2">-0.141 -34.9%</cell></row><row><cell cols="3">DIFFERENCE IN DIFFERENCE</cell><cell cols="2">-0.024 -1.0% 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Table7shows the hyperparameters (batch size, learning rate, dropout) that resulted in the optimal classification results for the ACL-ARC, ACT2, SCICITE, and MULTICITE datasets, respectively.Hyperparameters of each dataset</figDesc><table><row><cell>DATASET</cell><cell cols="3">batch size learning rate dropout</cell></row><row><cell>ACL-ARC</cell><cell>4</cell><cell>5e-05</cell><cell>0.1</cell></row><row><cell>ACT2</cell><cell>16</cell><cell>3e-05</cell><cell>0.1</cell></row><row><cell>SCICITE</cell><cell>16</cell><cell>3e-05</cell><cell>0.1</cell></row><row><cell>MULTICITE</cell><cell>8</cell><cell>5e-05</cell><cell>0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>Extended extraction results on the FINECITE Dataset.</figDesc><table><row><cell>1 back</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Extended results of the citation classification task on ACL-ARC.</figDesc><table><row><cell>.517</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Extended results of the citation classification task on SCICITE.</figDesc><table><row><cell/><cell/><cell cols="2">APPROACH</cell><cell>P</cell><cell>BACKGR. R F</cell><cell>METHOD P R F</cell><cell>RESULT P R F</cell><cell>MACRO P R F</cell><cell/></row><row><cell/><cell/><cell/><cell/><cell/><cell cols="2">Baseline Approaches</cell><cell/><cell/><cell/></row><row><cell/><cell/><cell cols="2">SCAFFOLDS</cell><cell cols="2">.863 .873 .868</cell><cell>.792 .792 .792</cell><cell>.827 .784 .804</cell><cell>.827 .816 .821</cell><cell/></row><row><cell/><cell/><cell cols="2">SCIBERT</cell><cell cols="2">.894 .862 .805</cell><cell>.805 .834 .819</cell><cell>.805 .855 .829</cell><cell>.835 .850 .842</cell><cell/></row><row><cell/><cell/><cell cols="2">GPT 4O</cell><cell cols="2">.860 .810 .834</cell><cell>.725 .821 .770</cell><cell>.671 .719 .694</cell><cell>.785 .784 .766</cell><cell/></row><row><cell/><cell/><cell cols="2">SCITULU</cell><cell cols="2">.803 .857 .829</cell><cell>.832 .726 .775</cell><cell>.720 .768 .743</cell><cell>.782 .784 .782</cell><cell/></row><row><cell/><cell/><cell/><cell/><cell/><cell cols="2">FINECITE Approaches</cell><cell/><cell/><cell/></row><row><cell/><cell/><cell cols="2">SCIBERT (Linear)</cell><cell cols="2">.886 .867 .876</cell><cell>.819 .812 .815</cell><cell>.796 .870 .831</cell><cell>.834 .850 .841</cell><cell/></row><row><cell/><cell/><cell cols="2">SCIBERT (BiLSTM)</cell><cell cols="2">.898 .862 .880</cell><cell>.823 .836 .829</cell><cell>.782 .875 .826</cell><cell>.834 .858 .845</cell><cell/></row><row><cell/><cell/><cell cols="2">SCIBERT (CRF)</cell><cell cols="2">.890 .863 .876</cell><cell>.827 .820 .822</cell><cell>.780 .874 .823</cell><cell>.832 .852 .841</cell><cell/></row><row><cell>APPROACH</cell><cell>P</cell><cell>BACKGR. R F</cell><cell>MOTIVATION P R F</cell><cell/><cell>USES P R F</cell><cell>EXTENDS P R F</cell><cell>SIMILARITY P R F</cell><cell>DIFFEREN. P R F</cell><cell>FUTUR P R F</cell><cell>MACRO</cell></row><row><cell/><cell/><cell/><cell/><cell/><cell cols="2">Baseline Approaches</cell><cell/><cell/><cell/></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Prof. Seonghyeon Lee</rs> for his insightful comments, and <rs type="person">Hwanseong Joo</rs> and <rs type="person">Jooyoung Yoon</rs> for their valuable feedback. We also acknowledge <rs type="person">Joel Thomas</rs>, <rs type="person">Minjoon Jin</rs>, and <rs type="person">Jialun Zheng</rs> for their initial contributions. This study was supported by the <rs type="funder">NRF</rs> grant (<rs type="grantNumber">RS-2018-NR031059</rs>) and the <rs type="programName">BK21 FOUR program</rs> (<rs type="grantNumber">41202420214871</rs>), both funded by the <rs type="funder">Ministry of Education of Korea. Access</rs> to the A100 GPU used in the experiments was provided by the Department of Data Convergence Computing at <rs type="institution">Kyungpook National University</rs>, where <rs type="person">Young-Kyoon Suh</rs> serves as an adjunct professor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VB4arXq">
					<idno type="grant-number">RS-2018-NR031059</idno>
					<orgName type="program" subtype="full">BK21 FOUR program</orgName>
				</org>
				<org type="funding" xml:id="_6QNmtnH">
					<idno type="grant-number">41202420214871</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Purpose and polarity of citation: Towards NLPbased bibliometrics</title>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Abu-Jbara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jefferson</forename><surname>Ezra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="596" to="606"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reference scope identification in citing sentences</title>
		<author>
			<persName><forename type="first">Amjad</forename><surname>Abu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Jbara</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="80" to="90"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Josh</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lama</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilge</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florencia</forename><surname>Leoni Aleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janko</forename><surname>Altenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Altman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">Shyamal Anadkat, et al. 2023. GPT-4 Technical Report</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detection of implicit citations for sentiment detection</title>
		<author>
			<persName><forename type="first">Awais</forename><surname>Athar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Detecting Structure in Scholarly Discourse</title>
		<meeting>the Workshop on Detecting Structure in Scholarly Discourse<address><addrLine>Jeju Island</addrLine></address></meeting>
		<imprint>
			<publisher>Korea. Association for Computational Linguistics</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="18" to="26"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SciB-ERT: A pretrained language model for scientific text</title>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1371</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3615" to="3620"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901"/>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Structural scaffolds for citation intent classification in scientific publications</title>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Field</forename><surname>Cady</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1361</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3586" to="3596"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46"/>
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A dataset of information-seeking questions and answers anchored in research papers</title>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.365</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4599" to="4610"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">From local to global: A graph rag approach to query-focused summarization</title>
		<author>
			<persName><forename type="first">Darren</forename><surname>Edge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ha</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newman</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apurva</forename><surname>Mody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Truitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Larson</surname></persName>
		</author>
		<idno>ArXiv, abs/2404.16130</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Structured Semantic Modeling of Scientific Citation Intents</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Ferrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Schifanella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Citation analysis as a tool in journal evaluation</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Garfield</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.178.4060.471</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="issue">4060</biblScope>
			<biblScope unit="page" from="471" to="479"/>
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<idno>GROBID. 2024</idno>
		<ptr target="https://github.com/kermitt2/grobid"/>
		<title level="m">GROBID: A Machine Learning Software for Extracting Information from Scholarly Documents</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780"/>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Technical brief: Agreement, the f-measure, and reliability in information retrieval</title>
		<author>
			<persName><forename type="first">George</forename><surname>Hripcsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">S</forename><surname>Rothschild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association : JAMIA</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="296" to="298"/>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Measuring the evolution of a scientific field through citation frames</title>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srijan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raine</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Mc-Farland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00028</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="391" to="406"/>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A meta-analysis of semantic classification of citations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Suchetha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drahomira</forename><surname>Kunnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Herrmannova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Pride</surname></persName>
		</author>
		<author>
			<persName><surname>Knoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quantitative Science Studies</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1170" to="1215"/>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML '01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML '01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An argument-annotated corpus of scientific publications</title>
		<author>
			<persName><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ponzetto</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5206</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Argument Mining</title>
		<meeting>the 5th Workshop on Argument Mining<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="40" to="46"/>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Investigating convolutional networks and domain-specific embeddings for semantic classification of citations</title>
		<author>
			<persName><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Paolo Ponzetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Eckert</surname></persName>
		</author>
		<idno type="DOI">10.1145/3127526.3127531</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Mining Scientific Publications</title>
		<meeting>the 6th International Workshop on Mining Scientific Publications<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="24" to="28"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MultiCite: Modeling realistic citations requires moving beyond the single-sentence singlelabel setting</title>
		<author>
			<persName><forename type="first">Anne</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailey</forename><surname>Kuehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.137</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1875" to="1889"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Retrieval-augmented generation for knowledgeintensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Kuttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.11401</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SciBERT sentence representation for citation context classification</title>
		<author>
			<persName><forename type="first">Himanshu</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavyajeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Scholarly Document Processing</title>
		<meeting>the Second Workshop on Scholarly Document Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="130" to="133"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overview of the 2021 SDP 3C citation context classification shared task</title>
		<author>
			<persName><forename type="first">N</forename><surname>Suchetha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kunnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drahomira</forename><surname>Pride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Herrmannova</surname></persName>
		</author>
		<author>
			<persName><surname>Knoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Scholarly Document Processing</title>
		<meeting>the Second Workshop on Scholarly Document Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="150" to="158"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic context extraction for citation classification</title>
		<author>
			<persName><forename type="first">Nambanoor</forename><surname>Suchetha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Kunnath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Pride</surname></persName>
		</author>
		<author>
			<persName><surname>Knoth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.aacl-main.41</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="549"/>
		</imprint>
	</monogr>
	<note>Long Papers) Online only. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An authoritative approach to citation classification</title>
		<author>
			<persName><forename type="first">David</forename><surname>Pride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Knoth</surname></persName>
		</author>
		<idno type="DOI">10.1145/3383583.3398617</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020, JCDL '20</title>
		<meeting>the ACM/IEEE Joint Conference on Digital Libraries in 2020, JCDL '20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="337" to="340"/>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The ACL Anthology network corpus</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahed</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><surname>Qazvinian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries (NLPIR4DL)</title>
		<meeting>the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries (NLPIR4DL)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="54" to="61"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fine-tuning language models on multiple datasets for citation intention classification</title>
		<author>
			<persName><forename type="first">Zeren</forename><surname>Shui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petros</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Karls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjian</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Manchanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ellad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tadmor</surname></persName>
		</author>
		<author>
			<persName><surname>Karypis</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.findings-emnlp.974</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2024</title>
		<meeting><address><addrLine>Miami, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="16718" to="16732"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">John</forename><surname>Swales</surname></persName>
		</author>
		<idno type="DOI">10.1093/applin/7.1.39</idno>
	</analytic>
	<monogr>
		<title level="j">Citation Analysis and Discourse Analysis. Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="56"/>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scientific argumentation detection as limited-domain intention recognition</title>
		<author>
			<persName><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Frontiers and Connections between Argumentation Theory and Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic classification of citation function</title>
		<author>
			<persName><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Tidhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="103" to="110"/>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Sciriff: A resource to enhance language model instruction-following over scientific literature</title>
		<author>
			<persName><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kejian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Daniel Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitzan</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Soldaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename><forename type="middle">Zejiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno>ArXiv, abs/2406.07835</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">HuggingFace's Transformers: Stateof-the-art Natural Language Processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>